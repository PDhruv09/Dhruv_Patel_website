<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Optimizing Transit in San Diego: My Map, My Mistakes</title>
        <link rel="stylesheet" href="assets/css/blogs_style.css"/>
    </head>
    <body>
        <main class="page">
            <article class="post" data-permalink-context="/Blogs/fashionmnist-dashboard-story.html">
                <header class="post-head">
                    <p class="post-meta">Oct 15, 2025 • 8 min</p>
                    <h1 id="title">FashionMNIST: Building a Model Comparison Dashboard</h1>
                </header>
                <section class="post-body">
                    <p>This started as a weekend experiment to compare a simple MLP with a CNN on FashionMNIST. It ended up becoming a dashboard I use to sanity-check models fast: not just accuracy numbers, but <strong>where</strong> they fail, <strong>how</strong> confident they are, and <strong>why</strong> those mistakes make sense.</p>

                    <h2 id="motivation">Motivation</h2>
                    <p>I’m guilty of celebrating a single metric. “Test accuracy = good ✅.” But accuracy hides interesting failures—like sandals mislabeled as sneakers with 99% confidence. I wanted a tool that forces me to look at <em>distribution</em> and <em>context</em>: class-wise performance, confusion patterns, and specific misclassifications.</p>
                    <p>So I built a Streamlit app that puts MLP vs. CNN <em>side-by-side</em> with the same dataset, same splits, and comparable training budgets. The goal: replace “one number” with a habit of visual inspection.</p>

                    <h2 id="process">Process &amp; Stuck Points</h2>
                    <p><strong>Training parity.</strong> Keeping comparisons fair was harder than expected. I standardized transforms, seeds, batch sizes, and epoch counts—and logged everything. Early runs looked “off” until I realized my MLP was evaluated on normalized inputs while the CNN used augmented images. Fixing that alone shifted the story.</p>
                    <p><strong>Confidence calibration.</strong> Raw softmax scores looked confident even when wrong. I added reliability curves and top-k confidence histograms. That surfaced a pattern: the CNN was <em>better</em> but also <em>bolder</em>, which matters if the model is part of a decision pipeline.</p>
                    <p><strong>Interactivity at scale.</strong> Rendering many misclassified tiles can be slow. Caching predictions (with a hash of model + params) and precomputing confusion matrices made the app snappy enough to explore.</p>

                    <h2 id="breakthroughs">Breakthroughs</h2>
                    <p><strong>Misclassifications are the gold.</strong> The dashboard highlights the <em>most confident wrong</em> predictions first. That’s where you learn: boots vs. sneakers, shirts vs. T-shirts. I also added a “contrast view” that shows where MLP fails but CNN succeeds (and vice-versa). That made the upgrade decision obvious.</p>
                    <p><strong>Human-readable insights.</strong> I annotate the confusion matrix cells with short notes (e.g., “texture overlap” or “silhouette ambiguity”). It nudges me to think in terms of features—not just labels.</p>
                    <p><strong>Shareable state.</strong> App URLs encode filters (class, threshold, model). Sending a link to “CNN, class=sandal, conf&gt;0.9, misclassified only” made discussions with friends way more concrete.</p>

                    <h2 id="reflections">Reflections</h2>
                    <p>This project changed my ML workflow. I now ship a <em>viewing tool</em> with a model—because inspection beats intuition. If I extend this, I’ll add Grad-CAMs, per-class PR curves, and a small active-learning loop to relabel the messiest tiles.</p>
                    <p>The biggest lesson? If your evaluation doesn’t change your next action, it’s not evaluation—it’s decoration.</p>

                    <aside class="post-cta">
                        <a class="btn" href="https://pdhruv09.github.io/DSC_170_GIS_SanDiego_Transit_Map/" target="_blank" rel="noopener">View the Interactive Map</a>
                        <a class="btn secondary" href="../projects/index.html">See All Projects</a>
                    </aside>
                </section>
                <!-- Back link -->
                <p><a href="./index.html">← Back to Blog</a></p>
            </article>
        </main>
        <!-- Footer (Common Contact Information) -->
        <footer id="footer">
            <!-- Social Media Page -->
            <section id="contact" class="left">
                <p>Contact Information</p>
                <p>Personal Email: dhruvkpatel004@gmail.com</p>
                <p>Work Email: dhruv.patel.imp@gmail.com</p>
                <p>Phone: +1 747-257-7194</p>
            </section>
            <!-- Social Media Page -->
            <section id="social" class="right">
                <h4>Social Media Handles</h4>
                <p><a href="https://www.linkedin.com/in/dhruv-patel-40b923228">LinkedIn</a></p>
                <p><a href="https://www.instagram.com/dhruvkpatel004?igsh=OGQ5ZDc2ODk2ZA%3D%3D&utm_source=qr">Instagram</a></p>
            </section>

        </footer>
        <script type="module" src="../global.js"></script>
        <script type="module" src="blogs.js" defer></script>

    </body>
</html>